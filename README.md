# ğŸ¤– ChatBot con WREN AI API

> **Interfaccia conversazionale intelligente per interrogare database aziendali usando linguaggio naturale**

Un'applicazione web moderna che sfrutta **WREN AI** per tradurre domande in linguaggio naturale in query SQL, permettendo analisi dati semplici ed intuitive. Include supporto vocale, visualizzazioni grafiche e un'interfaccia responsive.

![React](https://img.shields.io/badge/React-19.1.1-blue)
![TypeScript](https://img.shields.io/badge/TypeScript-5.6-blue)
![Vite](https://img.shields.io/badge/Vite-7.1.2-yellow)
![WREN AI](https://img.shields.io/badge/WREN_AI-Powered-green)

## ğŸŒŸ Caratteristiche Principali

### ğŸ§  **Powered by WREN AI**
- **Natural Language to SQL**: Trasforma domande in italiano in query SQL ottimizzate
- **Context-Aware**: Mantiene il contesto della conversazione per domande di follow-up
- **Intelligent Responses**: Risposte elaborate e formattate da AI
- **Streaming Support**: Risposte in tempo reale con feedback progressivo

### ğŸ¤ **Input Vocale**
- Riconoscimento vocale in italiano tramite Web Speech API
- Interfaccia hands-free con feedback visivo
- Pulsante microfono con animazione durante l'ascolto
- CompatibilitÃ  multi-browser (Chrome, Edge, Opera)

### ğŸ“Š **Visualizzazioni Dati**
- Grafici interattivi generati automaticamente con Vega-Lite
- Rendering markdown avanzato per risposte formattate
- Tabelle dati responsive e leggibili
- Supporto per domande analitiche complesse

### ğŸ“± **Design Moderno**
- Interfaccia responsive ottimizzata per desktop, tablet e mobile
- Design pulito con effetti glassmorphism
- Animazioni fluide e transizioni
- Dark/light mode friendly

## ğŸš€ Quick Start

### Prerequisiti
- **Node.js** 18+ 
- **WREN AI Engine** in esecuzione (locale o remoto)
- Database configurato e connesso a WREN

### Installazione

```bash
# Clona il repository
git clone https://github.com/Attilio81/ChatBotWRENAI_API.git
cd ChatBotWRENAI_API

# Installa le dipendenze
npm install

# Avvia il development server
npm run dev
```

L'applicazione sarÃ  disponibile su `http://localhost:5173`

### Configurazione WREN AI

1. **Configura il proxy Vite** (giÃ  incluso in `vite.config.ts`):
```typescript
server: {
  proxy: {
    '/wren-api': {
      target: 'http://localhost:8080',  // URL WREN AI Engine
      changeOrigin: true,
      rewrite: (path) => path.replace(/^\/wren-api/, '')
    }
  }
}
```

2. **Avvia WREN AI Engine** con il tuo modello dati configurato

3. **Test della connessione**: Usa gli script di test inclusi
```bash
node test_wren_api.js      # Test API standard
node test_wren_stream.cjs  # Test streaming
```

## ğŸ—ï¸ Architettura

### Frontend Stack
```
React 19.1.1 + TypeScript 5.6 + Vite 7.1.2
â”œâ”€â”€ UI Framework: Material-UI (MUI)
â”œâ”€â”€ Charting: Vega + Vega-Lite + Vega-Embed
â”œâ”€â”€ Markdown: marked
â””â”€â”€ Voice: Web Speech API
```

### Backend Integration
```
User Question â†’ WREN AI Engine â†’ SQL Generation â†’ Database Query â†’ AI Response â†’ UI
```

### Componenti Principali

```
src/
â”œâ”€â”€ components/
â”‚   â”œâ”€â”€ AgentSelector.tsx      # Landing page selezione modalitÃ 
â”‚   â”œâ”€â”€ ChatHeader.tsx         # Header con info sessione
â”‚   â”œâ”€â”€ ChatMessages.tsx       # Visualizzazione conversazione
â”‚   â”œâ”€â”€ ChatInput.tsx          # Input testo + microfono
â”‚   â”œâ”€â”€ MessageBubble.tsx      # Rendering singoli messaggi
â”‚   â”œâ”€â”€ ChartRenderer.tsx      # Grafici Vega-Lite
â”‚   â””â”€â”€ QuickQuestions.tsx     # Domande suggerite
â”œâ”€â”€ services/
â”‚   â””â”€â”€ wren.ts                # Client API WREN AI
â”œâ”€â”€ hooks/
â”‚   â”œâ”€â”€ useChat.ts             # Logica gestione chat
â”‚   â””â”€â”€ useVoiceRecognition.ts # Web Speech API wrapper
â””â”€â”€ types/
    â”œâ”€â”€ index.ts               # Type definitions
    â””â”€â”€ speech.d.ts            # Web Speech API types
```

## ğŸ“‹ Comandi Disponibili

```bash
npm run dev      # Avvia development server con hot reload
npm run build    # Build di produzione
npm run lint     # Verifica qualitÃ  codice con ESLint
npm run preview  # Preview build di produzione
```

## ğŸ’¡ Esempi d'Uso

### Domande Analitiche Base
```
ğŸ‘¤ "Mostrami i 10 articoli piÃ¹ costosi"
ğŸ¤– Genera e esegue: SELECT TOP 10 * FROM articoli ORDER BY prezzo DESC

ğŸ‘¤ "Quanti prodotti abbiamo in giacenza?"
ğŸ¤– Conta articoli con giacenza > 0 e fornisce il totale

ğŸ‘¤ "Trova tutti gli spettrofotometri"
ğŸ¤– Filtra per nome prodotto con LIKE '%spettrofotometro%'
```

### Domande con Follow-up
```
ğŸ‘¤ "Mostrami le vendite di gennaio"
ğŸ¤– [Genera query per vendite gennaio]

ğŸ‘¤ "E quelle di febbraio?"
ğŸ¤– [Usa il contesto per generare query simile per febbraio]

ğŸ‘¤ "Confrontale"
ğŸ¤– [Genera query comparativa con entrambi i mesi]
```

### Visualizzazioni Grafiche
```
ğŸ‘¤ "Crea un grafico delle vendite mensili"
ğŸ¤– Genera query + specifica Vega-Lite per bar chart

ğŸ‘¤ "Mostra la distribuzione dei prezzi"
ğŸ¤– Crea istogramma interattivo con Vega
```

## ğŸ® Guida Utilizzo

### 1. **Avvio Applicazione**
All'apertura vedrai la landing page con:
- Info sul progetto e WREN AI
- Accesso diretto alla chat
- (Opzionale) Selezione di modalitÃ  o agenti se implementati

### 2. **Interazione Chat**

**Testo**:
- Digita la domanda nella textarea
- Premi `Invio` o clicca l'icona ğŸ“¤
- Attendi la risposta con streaming progressivo

**Voce**:
1. Clicca il pulsante ğŸ¤ (diventa rosso)
2. Concedi permessi microfono se richiesto
3. Parla chiaramente in italiano
4. Il testo viene trascritto automaticamente
5. Clicca di nuovo per fermare o invia direttamente

### 3. **Domande Rapide**
- Usa i suggerimenti precompilati per iniziare
- Personalizza le domande nel componente `QuickQuestions.tsx`
- Perfette per onboarding nuovi utenti

### 4. **Visualizzazioni**
- I grafici appaiono automaticamente quando pertinenti
- Interattivi: hover, zoom, pan
- Esportabili come immagine

### 5. **Gestione Sessione**
- Ogni conversazione ha un Thread ID univoco
- Il contesto viene mantenuto per follow-up
- Ricarica la pagina per iniziare una nuova sessione

## ğŸ”§ Configurazione Avanzata

### WREN AI Endpoints

Il servizio `wren.ts` espone questi metodi:

```typescript
// Domanda singola
await wrenService.ask(question, threadId?)

// Lista modelli disponibili
await wrenService.getModels()

// Genera grafico Vega-Lite
await wrenService.generateVegaChart(question, sql)

// Streaming response (async generator)
for await (const chunk of wrenService.askStream(question, threadId)) {
  console.log(chunk.delta);
}
```

### Personalizzazione

**Modifica colori e stili**: Edita i file `.css` in `src/components/`

**Aggiungi nuove domande rapide**: In `QuickQuestions.tsx`
```typescript
const questions = [
  "La tua domanda personalizzata qui",
  // ...
];
```

**Cambia comportamento WREN**: In `src/services/wren.ts`
```typescript
constructor(baseUrl: string = '/wren-api') {
  this.baseUrl = baseUrl; // Cambia endpoint
}
```

## ğŸ› ï¸ Stack Tecnologico Completo

| Layer | Tecnologia | Versione | Scopo |
|-------|-----------|----------|-------|
| **Frontend** | React | 19.1.1 | UI Framework |
| | TypeScript | 5.6 | Type Safety |
| | Vite | 7.1.2 | Build Tool |
| **UI Components** | Material-UI | 7.3.2 | Component Library |
| | Emotion | 11.14.0 | CSS-in-JS |
| **Data Viz** | Vega | 6.2.0 | Grammar of Graphics |
| | Vega-Lite | 6.4.1 | High-level Viz |
| | Vega-Embed | 7.1.0 | React Integration |
| **Text** | marked | 16.3.0 | Markdown Parser |
| **AI Backend** | WREN AI | - | NL2SQL Engine |
| **Voice** | Web Speech API | Native | Voice Recognition |

## ğŸš€ Deployment

### Build Production

```bash
npm run build
```

Genera la cartella `dist/` pronta per il deploy.

### Deploy su Vercel/Netlify

```bash
# Vercel
vercel --prod

# Netlify
netlify deploy --prod --dir=dist
```

âš ï¸ **Importante**: Configura le variabili d'ambiente per puntare a WREN AI in produzione.

### Docker (Opzionale)

```dockerfile
FROM node:18-alpine
WORKDIR /app
COPY package*.json ./
RUN npm ci --only=production
COPY . .
RUN npm run build
EXPOSE 5173
CMD ["npm", "run", "preview"]
```

## ğŸ› Troubleshooting

### Problemi Comuni

**ğŸ”´ WREN AI non risponde**
- âœ… Verifica che WREN AI Engine sia in esecuzione
- âœ… Controlla l'URL nel proxy Vite (`vite.config.ts`)
- âœ… Testa con `node test_wren_api.js`
- âœ… Controlla i log del browser (F12 â†’ Network)

**ğŸ¤ Input vocale non funziona**
- âœ… Usa Chrome, Edge o Opera (Firefox/Safari hanno supporto limitato)
- âœ… Verifica permessi microfono nelle impostazioni browser
- âœ… Assicurati di essere su HTTPS o localhost
- âœ… Controlla che il microfono funzioni in altre app

**ğŸ“Š Grafici non si visualizzano**
- âœ… Verifica che Vega-Embed sia installato: `npm list vega-embed`
- âœ… Controlla errori console per specifica Vega non valida
- âœ… Assicurati che WREN restituisca una specifica Vega-Lite valida

**âš¡ Performance lente**
- âœ… Abilita streaming per risposte piÃ¹ rapide (giÃ  implementato)
- âœ… Ottimizza le query WREN lato database
- âœ… Usa build di produzione (`npm run build`)

### Debug Avanzato

**Console Browser**: 
```javascript
// F12 â†’ Console
// Abilita verbose logging
localStorage.setItem('debug', 'wren:*');
```

**Network Inspection**:
- F12 â†’ Network â†’ Filtra per `/wren-api`
- Controlla payload request/response
- Verifica timing e status codes

## ğŸ“„ Documentazione Aggiuntiva

- **WREN AI**: [Documentazione ufficiale](https://github.com/Canner/WrenAI)
- **Vega-Lite**: [Specifica e esempi](https://vega.github.io/vega-lite/)
- **Web Speech API**: [MDN Documentation](https://developer.mozilla.org/en-US/docs/Web/API/Web_Speech_API)

## ğŸ¤ Contributi

Progetto aperto a miglioramenti! Per contribuire:

1. Fork del repository
2. Crea un branch feature (`git checkout -b feature/AmazingFeature`)
3. Commit delle modifiche (`git commit -m 'Add AmazingFeature'`)
4. Push al branch (`git push origin feature/AmazingFeature`)
5. Apri una Pull Request

## ğŸ“ License

Questo progetto Ã¨ privato e proprietario di EGM.

---

**Versione**: 3.0.0  
**Ultimo aggiornamento**: Novembre 2025  
**Caratteristiche**: WREN AI Integration, Voice Input, Vega Charts, Streaming Responses
